# ACP : Analyse en Composantes Principales

## Résumé de l’ACP
L’Analyse en Composantes Principales (ACP) est une méthode statistique utilisée pour réduire la dimensionnalité d’un ensemble de données tout en conservant un maximum d’information. Elle transforme des variables corrélées en un nouvel ensemble de variables non corrélées, appelées composantes principales. Ces composantes sont ordonnées de sorte que la première explique le plus de variance possible, la seconde le second plus grand montant de variance, etc.  

L’ACP est souvent utilisée en exploration de données, en visualisation (notamment quand on a des données multidimensionnelles), et en prétraitement pour des modèles d’apprentissage automatique.  


## Détails de l’ACP

1. Objectif  
L’ACP cherche à résumer l’information contenue dans un grand nombre de variables en un plus petit nombre de nouvelles variables, tout en minimisant la perte d’information.  

2. Étapes du calcul  

    1. Standardisation des données  
       - Comme l’ACP est influencée par l’échelle des variables, on commence par centrer et réduire les données (moyenne 0 et écart-type 1 pour chaque variable).  
     
    2. Calcul de la matrice de covariance (ou de corrélation)  
       - Cette matrice indique comment les variables sont liées entre elles.  
       - Si les variables sont sur des échelles différentes, on privilégie la matrice de corrélation plutôt que celle de covariance.  

    3. Décomposition en valeurs propres et vecteurs propres  
       - On calcule les valeurs propres et les vecteurs propres de la matrice de covariance.  
       - Les valeurs propres mesurent la variance expliquée par chaque composante principale.  
       - Les vecteurs propres (aussi appelés composantes principales) définissent la direction des nouvelles variables.  

    4. Sélection des composantes principales  
       - On choisit les composantes qui expliquent le plus de variance en regardant le cumul des valeurs propres.  
       - Un critère courant est de conserver assez de composantes pour expliquer 80-90% de la variance.  
       - On peut aussi utiliser le critère du coude, qui consiste à repérer un point où l'ajout d'une nouvelle composante n'apporte plus beaucoup de gain en variance.  

    5. Projection des données sur les nouvelles composantes  
       - Les données initiales sont transformées dans ce nouvel espace formé par les composantes principales.  
       - Cela permet une visualisation en 2D ou 3D si on conserve seulement 2 ou 3 composantes.  

 3. Applications courantes de l’ACP  

- Visualisation des données : Par exemple, en biologie, l’ACP est utilisée pour explorer des groupes d’individus en génétique.  
- Compression de données : Utile dans l’apprentissage automatique pour réduire le nombre de dimensions et accélérer les algorithmes.  
- Détection d’anomalies : Une observation qui se projette loin des autres sur les premières composantes pourrait être une anomalie.  
- Prétraitement en Machine Learning : L’ACP peut aider à réduire la colinéarité entre variables et améliorer la performance des modèles prédictifs.  


## Exemple détaillé d’ACP

Nous allons appliquer l’ACP sur un jeu de données fictif contenant les caractéristiques de clients d’une banque. L’objectif est de réduire la dimensionnalité tout en conservant un maximum d’information pour mieux comprendre la structure des données.

 1. Jeu de données  
Imaginons que nous avons une base de 10 clients avec les caractéristiques suivantes :  

| Client | Revenu annuel (€) | Score crédit | Age | Montant épargne (€) |
|--------|------------------|-------------|-----|---------------------|
| A      | 35000            | 650         | 25  | 12000               |
| B      | 40000            | 700         | 30  | 15000               |
| C      | 25000            | 500         | 22  | 8000                |
| D      | 60000            | 800         | 45  | 30000               |
| E      | 70000            | 850         | 50  | 40000               |
| F      | 20000            | 480         | 20  | 5000                |
| G      | 55000            | 770         | 40  | 27000               |
| H      | 30000            | 580         | 27  | 11000               |
| I      | 45000            | 720         | 33  | 17000               |
| J      | 65000            | 810         | 47  | 35000               |

Les variables sont corrélées :  
- Un revenu plus élevé est souvent lié à une meilleure épargne et un meilleur score crédit.  
- L’âge peut influencer la capacité d’épargne.  

Nous allons utiliser l’ACP pour réduire ces 4 variables en 2 composantes principales tout en conservant un maximum d’information.

 2. Étapes de l’ACP  

 1️⃣ Standardisation des données  
L’ACP est influencée par l’échelle des variables, donc nous les centrons et réduisons (moyenne = 0, écart-type = 1).  

Formule de standardisation :  
\[
X_{\text{standardisé}} = \frac{X - \text{moyenne}(X)}{\text{écart-type}(X)}
\]

Après transformation, nous obtenons une nouvelle table où chaque variable a une moyenne de 0 et un écart-type de 1.

 2️⃣ Calcul de la matrice de covariance  
Nous calculons la matrice de covariance entre les variables. Elle montre comment elles varient ensemble.  

Exemple (valeurs fictives) :  
\[
\begin{bmatrix}
1.00 & 0.85 & 0.60 & 0.90 \\
0.85 & 1.00 & 0.55 & 0.88 \\
0.60 & 0.55 & 1.00 & 0.50 \\
0.90 & 0.88 & 0.50 & 1.00
\end{bmatrix}
\]
où :  
- 1.00 = une variable est parfaitement corrélée avec elle-même.  
- 0.85 entre "Revenu annuel" et "Score crédit" montre qu’ils sont fortement corrélés.  
- 0.50 entre "Age" et "Montant épargne" indique une corrélation plus faible.

 3️⃣ Calcul des valeurs propres et vecteurs propres  
Nous trouvons les valeurs propres et vecteurs propres pour obtenir les nouvelles directions des composantes principales.  

Exemple (valeurs fictives) :  

| Composante principale | Valeur propre | Variance expliquée (%) |
|----------------------|--------------|----------------------|
| CP1                  | 2.8          | 70%                  |
| CP2                  | 1.0          | 25%                  |
| CP3                  | 0.15         | 4%                   |
| CP4                  | 0.05         | 1%                   |

On voit que les deux premières composantes expliquent 95% de la variance. On peut donc réduire nos 4 variables à 2 composantes.

 4️⃣ Choix du nombre de composantes  
On utilise le critère du coude (voir graphique ci-dessous).  

🔽 Graphique de la somme des variances expliquées  
_(Ajoutons une image pour illustrer le critère du coude)_  

> _Une image montrant une courbe décroissante où la variance expliquée diminue fortement après CP2, justifiant le choix de 2 composantes._

 5️⃣ Projection des données sur les nouvelles composantes  
On transforme les anciennes variables en nouvelles coordonnées dans l’espace des composantes principales.  

| Client | CP1  | CP2  |
|--------|------|------|
| A      | -1.2 | 0.8  |
| B      | -0.8 | 1.0  |
| C      | -1.8 | -0.5 |
| D      | 1.5  | -1.2 |
| E      | 2.2  | -1.5 |
| F      | -2.0 | -0.8 |
| G      | 1.2  | -0.9 |
| H      | -1.0 | 0.5  |
| I      | -0.5 | 1.2  |
| J      | 1.8  | -1.0 |

🔽 Graphique de projection des clients sur CP1 et CP2  
_(Ajoutons un scatter plot des clients dans le nouvel espace des composantes principales)_  

> _Une image montrant un graphe avec deux axes (CP1 et CP2), où les clients sont positionnés selon leurs nouvelles coordonnées._

---

 3. Interprétation des résultats  

- CP1 (70% de la variance) : Oppose les clients avec un faible revenu, faible épargne, et score crédit bas (valeurs négatives) aux clients riches, avec une forte épargne et un bon score crédit (valeurs positives).  
- CP2 (25% de la variance) : Semble être influencée par l’âge et des comportements d’épargne distincts.  

On peut maintenant visualiser et segmenter les clients facilement avec ces deux dimensions au lieu des 4 d’origine.

---

 4. Conclusion  

✅ Réduction de dimension : De 4 à 2 variables tout en conservant 95% de l’information.  
✅ Visualisation plus facile des groupes de clients.  
✅ Aide à la segmentation pour du marketing bancaire (ex : clients jeunes & petits revenus vs. seniors & gros épargnants).  

---

1. Graphique du critère du coude 📈 

2. Scatter plot des clients dans l’espace des composantes principales 🔵🔴  

==========================================================================================================================
